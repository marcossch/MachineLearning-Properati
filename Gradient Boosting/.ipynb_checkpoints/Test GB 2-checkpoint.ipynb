{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se carga el set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = pickle.load(open(\"../../Data.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OJO CON ESTO\n",
    "proper = pickle.load(open(\"../../test_data_full.p\", \"rb\"))\n",
    "#agrego el set de pruebas con los datos posta al de entrenamiento\n",
    "propTOT = pd.merge(proper, prop, how=\"outer\")\n",
    "#completo las superficies totales con las cubiertas\n",
    "propTOT['surface_total_in_m2'] = propTOT.apply(lambda row: row[12] if(np.all(pd.isnull(row[11]))) else row[11], axis=1)\n",
    "#cortamos por precios\n",
    "propTOT = propTOT[(propTOT['price_usd_per_m2']<7000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division del set de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se formatea lat y lon\n",
    "p = propTOT[['property_type','place_name','surface_total_in_m2',\\\n",
    "          'price_usd_per_m2','latlon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'price_aprox_usd', 'state_name']]\n",
    "p.dropna(inplace = True)\n",
    "\n",
    "p['lat'] = p.apply(lambda row: row[4][0], axis=1)\n",
    "\n",
    "p['lon'] = p.apply(lambda row: row[4][1], axis=1)\n",
    "\n",
    "p = p[['property_type','place_name','surface_total_in_m2',\\\n",
    "          'price_usd_per_m2','lat','lon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'price_aprox_usd', 'state_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se le asigna un valor numerico al tipo de propiedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignarPT( p ):\n",
    "    if p == 'apartment':\n",
    "        return 3\n",
    "    if p == 'house':\n",
    "        return 2.25\n",
    "    if p == 'store':\n",
    "        return 6.5\n",
    "    return 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['property_type'] = p.apply(lambda x: asignarPT(x[0]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se le asigna un valor numerico a la ubicacion CABA o GBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignarLT( p ):\n",
    "    if p == 'Capital Federal':\n",
    "        return 0\n",
    "    return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['location_type'] = p.apply(lambda x: asignarLT(x[10]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se le asigna un valor a los barrios segun el analisis de grupos hecho en el tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignarPV(name, dic):\n",
    "    return dic[name]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoodGroups = p[[\"place_name\", \"price_usd_per_m2\", \"Cant_ParadasTransporte\"]]\n",
    "hoodGroups = hoodGroups.groupby(\"place_name\").agg([np.mean]).reset_index()\n",
    "hoodGroups = hoodGroups.sort_values(by=(\"price_usd_per_m2\", \"mean\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGdics = {}\n",
    "precio_ant = 0\n",
    "val_ant = 0\n",
    "for row in hoodGroups.iterrows():\n",
    "    name = row[1][0]\n",
    "    price = row[1][1]\n",
    "    val = val_ant + (precio_ant/price)*100\n",
    "    HGdics[name] = val\n",
    "    precio_ant = price\n",
    "    val_ant = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[\"place_value\"] = p.apply(lambda x: asignarPV(x[1], HGdics), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pEnt = p[['property_type','surface_total_in_m2',\\\n",
    "          'lat','lon','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'place_value', 'price_aprox_usd', 'Cant_ColeYUniv', 'location_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pEnt.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### estimo las superficies para el set de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoodGroups = p[[\"place_name\", 'surface_total_in_m2']]\n",
    "hoodGroups = hoodGroups.groupby(\"place_name\").agg([np.mean]).reset_index()\n",
    "hoodGroups = hoodGroups.sort_values(by=(\"surface_total_in_m2\", \"mean\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGSdics = {}\n",
    "for row in hoodGroups.iterrows():\n",
    "    name = row[1][0]\n",
    "    supr = row[1][1]\n",
    "    HGSdics[name] = supr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se carga el set de Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBA Random Forest Regresivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper = pickle.load(open(\"../../test_data_full.p\", \"rb\"))\n",
    "\n",
    "#se formatea lat y lon\n",
    "p = proper[['property_type','place_name','surface_total_in_m2','surface_covered_in_m2',\\\n",
    "          'latlon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'price_aprox_usd', 'state_name']]\n",
    "\n",
    "p['lat'] = p.apply(lambda row: row[4][0] if(np.all(pd.notnull(row[4]))) else row[4], axis=1)\n",
    "\n",
    "p['lon'] = p.apply(lambda row: row[4][1] if(np.all(pd.notnull(row[4]))) else row[4], axis=1)\n",
    "\n",
    "p = p[['property_type','place_name','surface_total_in_m2','surface_covered_in_m2',\\\n",
    "          'lat','lon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'price_aprox_usd', 'state_name']]\n",
    "\n",
    "p['property_type'] = p.apply(lambda x: asignarPT(x[0]), axis = 1)\n",
    "\n",
    "def asignarPVsegunEnt(name):\n",
    "    if(HGdics.has_key(name)):\n",
    "        return HGdics[name]\n",
    "    return np.nan\n",
    "\n",
    "#hay que armar los hoodGropus segun los resultados del set de Entrenamiento\n",
    "p[\"place_value\"] = p.apply(lambda x: asignarPVsegunEnt(x[1]), axis=1)\n",
    "\n",
    "def asignarLT( p ):\n",
    "    if p == 'Capital Federal':\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "p['location_type'] = p.apply(lambda x: asignarLT(x[10]), axis = 1)\n",
    "\n",
    "#completo las superficies totales con las cubiertas\n",
    "p['surface_total_in_m2'] = p.apply(lambda row: row[3] if(np.all(pd.isnull(row[2]))) else row[2], axis=1)\n",
    "\n",
    "pPru = p[['property_type','surface_total_in_m2',\\\n",
    "        'lat','lon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'place_value', 'price_aprox_usd', 'place_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimo los valores nan del set de pruebas de superficies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignarSupFaltantes(HGSdics, sup, barrio):\n",
    "    if (np.isnan(sup) & HGSdics.has_key(barrio)):\n",
    "        return HGSdics[barrio]\n",
    "    return sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pPru['surface_total_in_m2'] = pPru.apply(lambda x: asignarSupFaltantes(HGSdics, x[1], x[9]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pEnt['surface_total_in_m2_n'] = pEnt.apply(lambda x: x[1]*10, axis=1)\n",
    "#pPru['surface_total_in_m2_n'] = pEnt.apply(lambda x: x[1]*10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split del dataset para entrenamiento y pruebas, 80% y 20% respectivamente\n",
    "Xtrn, Xtest, Ytrn, Ytest = train_test_split(pEnt[['property_type','surface_total_in_m2',\n",
    "        'place_value']],pEnt[['price_aprox_usd']],test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir el modelo a probar\n",
    "model = GradientBoostingRegressor(loss = 'ls', n_estimators = 500, max_depth = 5, learning_rate = 0.15)\n",
    "\n",
    "#fit model on training dataset\n",
    "model.fit(Xtrn, Ytrn['price_aprox_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediccion \n",
    "pred = mean_squared_error(Ytrn['price_aprox_usd'], model.predict(Xtrn))\n",
    "print ('RMSE_Price', pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrar esto, es solo para probar\n",
    "#pPru.dropna(subset=['price_aprox_usd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "#hay que llenar el resto de los valores nan\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = Imputer(missing_values=np.nan, strategy='most_frequent', axis=1)\n",
    "imp = imp.fit(Xtrn)\n",
    "\n",
    "pPru_imp = imp.transform(pPru[['property_type','surface_total_in_m2',\n",
    "        'place_value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediccion \n",
    "#pred = mean_squared_error(pPru['price_aprox_usd'], model.predict(pPru_imp))\n",
    "#print ('RMSE_Price', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pPru['price_usd'] = model.predict(pPru_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"id\"] = proper[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"price_usd\"] = pPru['price_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(index=False, path_or_buf=\"resultsGB2PhiAlpha.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para ver mas o menos que tan lejos quedo\n",
    "result[\"real_price_usd\"] = proper['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
