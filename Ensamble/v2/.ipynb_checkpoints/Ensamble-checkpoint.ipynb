{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargo los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop = pickle.load(open(\"../../../datos/Data.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proper = pickle.load(open(\"../../../datos/propiedadesPruebaConColTransGas.p\", \"rb\"))\n",
    "\n",
    "propTOT = pd.merge(proper, prop, how=\"outer\")\n",
    "\n",
    "propTOT['surface_total_in_m2'] = propTOT.apply(lambda row: row[12] if(np.all(pd.isnull(row[11]))) else row[11], axis=1)\n",
    "\n",
    "propTOT = propTOT[(propTOT['price_usd_per_m2']<8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#se formatea lat y lon\n",
    "p = propTOT[['property_type','place_name','surface_total_in_m2',\\\n",
    "          'price_usd_per_m2','latlon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'price_aprox_usd']]\n",
    "p.dropna(inplace = True)\n",
    "\n",
    "p['lat'] = p.apply(lambda row: row[4][0], axis=1)\n",
    "\n",
    "p['lon'] = p.apply(lambda row: row[4][1], axis=1)\n",
    "\n",
    "p = p[['property_type','place_name','surface_total_in_m2',\\\n",
    "          'price_usd_per_m2','lat','lon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'price_aprox_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def asignarPT( p ):\n",
    "    if p == 'apartment':\n",
    "        return 0\n",
    "    if p == 'house':\n",
    "        return 1\n",
    "    if p == 'store':\n",
    "        return 2\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p['property_type'] = p.apply(lambda x: asignarPT(x[0]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def asignarPV(name, dic):\n",
    "    return dic[name]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hoodGroups = p[[\"place_name\", \"price_usd_per_m2\"]]\n",
    "hoodGroups = hoodGroups.groupby(\"place_name\").agg([np.mean]).reset_index()\n",
    "hoodGroups = hoodGroups.sort_values(by=(\"price_usd_per_m2\", \"mean\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HGdics = {}\n",
    "precio_ant = 0\n",
    "val_ant = 0\n",
    "for row in hoodGroups.iterrows():\n",
    "    name = row[1][0]\n",
    "    price = row[1][1]\n",
    "    val = val_ant + (precio_ant/price)\n",
    "    HGdics[name] = val\n",
    "    precio_ant = price\n",
    "    val_ant = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p[\"place_value\"] = p.apply(lambda x: asignarPV(x[1], HGdics), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pEnt = p[['property_type','surface_total_in_m2',\\\n",
    "          'lat','lon','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'place_value', 'price_aprox_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pEnt.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "proper = pickle.load(open(\"../../../datos/propiedadesPruebaConColTransGas.p\", \"rb\"))\n",
    "\n",
    "#se formatea lat y lon\n",
    "p = proper[['property_type','place_name','surface_total_in_m2','surface_covered_in_m2',\\\n",
    "          'latlon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'price_aprox_usd']]\n",
    "\n",
    "p['lat'] = p.apply(lambda row: row[4][0] if(np.all(pd.notnull(row[5]))) else row[5], axis=1)\n",
    "\n",
    "p['lon'] = p.apply(lambda row: row[4][1] if(np.all(pd.notnull(row[5]))) else row[5], axis=1)\n",
    "\n",
    "p = p[['property_type','place_name','surface_total_in_m2','surface_covered_in_m2',\\\n",
    "          'lat','lon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'price_aprox_usd']]\n",
    "\n",
    "p['property_type'] = p.apply(lambda x: asignarPT(x[0]), axis = 1)\n",
    "\n",
    "def asignarPVsegunEnt(name):\n",
    "    if(HGdics.has_key(name)):\n",
    "        return HGdics[name]\n",
    "    return np.nan\n",
    "\n",
    "#hay que armar los hoodGropus segun los resultados del set de Entrenamiento\n",
    "p[\"place_value\"] = p.apply(lambda x: asignarPVsegunEnt(x[1]), axis=1)\n",
    "\n",
    "#completo las superficies totales con las cubiertas\n",
    "p['surface_total_in_m2'] = p.apply(lambda row: row[3] if(np.all(pd.isnull(row[2]))) else row[2], axis=1)\n",
    "\n",
    "pPru = p[['property_type','surface_total_in_m2',\\\n",
    "        'lat','lon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'place_value', 'price_aprox_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrn, Xtest, Ytrn, Ytest = train_test_split(pEnt[['property_type','surface_total_in_m2',\n",
    "        'place_value']],pEnt[['price_aprox_usd']],test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = RandomForestRegressor(n_estimators=10, max_features='auto', min_samples_leaf=1, min_samples_split=4, bootstrap=True)\n",
    "estimators.append(('rfr',model1))\n",
    "\n",
    "model2 = GradientBoostingRegressor(loss = 'ls', n_estimators = 500, max_depth = 5, learning_rate = 0.15)\n",
    "estimators.append(('gbr',model2))\n",
    "\n",
    "\"\"\"\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\"\"\"\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rfr', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=4,\n",
       "           min_weight_fraction_leaf=0.0, ...s=500, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.fit(Xtrn, Ytrn['price_aprox_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "#hay que llenar el resto de los valores nan\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = Imputer(missing_values=np.nan, strategy='most_frequent', axis=1)\n",
    "imp = imp.fit(Xtrn)\n",
    "\n",
    "pPru_imp = imp.transform(pPru[['property_type','surface_total_in_m2',\n",
    "        'place_value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8b6800633916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpPru\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_usd'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpPru_imp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/voting_classifier.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 lambda x: np.argmax(\n\u001b[1;32m    224\u001b[0m                     np.bincount(x, weights=self._weights_not_none)),\n\u001b[0;32m--> 225\u001b[0;31m                 axis=1, arr=predictions)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mmaj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/facundo/.local/lib/python2.7/site-packages/numpy/lib/shape_base.pyc\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot apply_along_axis when any iteration dimensions are 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# build a buffer for storing evaluations of func1d.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/voting_classifier.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    222\u001b[0m             maj = np.apply_along_axis(\n\u001b[1;32m    223\u001b[0m                 lambda x: np.argmax(\n\u001b[0;32m--> 224\u001b[0;31m                     np.bincount(x, weights=self._weights_not_none)),\n\u001b[0m\u001b[1;32m    225\u001b[0m                 axis=1, arr=predictions)\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "pPru['price_usd'] = ensemble.predict(pPru_imp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
