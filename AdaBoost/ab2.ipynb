{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop = pickle.load(open(\"../../datos/Data.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nos quedamos con la parte del set de datos que nos importa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "p = prop[['property_type','place_name','surface_total_in_m2','surface_covered_in_m2',\\\n",
    "          'price_usd_per_m2','latlon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_LugaresTuristicos','Cant_ParadasTransporte','price_aprox_usd']]\n",
    "p.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separamos la Latitud-Longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "p['lat'] = p.apply(lambda row: row[5][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facundo/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "p['lon'] = p.apply(lambda row: row[5][1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = p[['property_type','place_name','surface_total_in_m2','surface_covered_in_m2',\\\n",
    "          'price_usd_per_m2','lat','lon','Cant_ColeYUniv','Cant_LocalesGastronomicos',\n",
    "         'Cant_LugaresTuristicos','Cant_ParadasTransporte','price_aprox_usd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asignamos un valor numerico al tipo de propiedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def asignarPT( p ):\n",
    "    if p == 'apartment':\n",
    "        return 3\n",
    "    if p == 'house':\n",
    "        return 2.25\n",
    "    if p == 'store':\n",
    "        return 6.5\n",
    "    return 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p['property_type'] = p.apply(lambda x: asignarPT(x[0]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asignamos un valor a los barrios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def asignarPV(name, dic):\n",
    "    return dic[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hoodGroups = p[[\"place_name\", \"price_usd_per_m2\"]]\n",
    "hoodGroups = hoodGroups.groupby(\"place_name\").agg([np.mean]).reset_index()\n",
    "hoodGroups = hoodGroups.sort_values(by=(\"price_usd_per_m2\", \"mean\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HGdics = {}\n",
    "precio_ant = 0\n",
    "val_ant = 0\n",
    "for row in hoodGroups.iterrows():\n",
    "    name = row[1][0]\n",
    "    price = row[1][1]\n",
    "    val = val_ant + (precio_ant/price)*10\n",
    "    HGdics[name] = val\n",
    "    precio_ant = price\n",
    "    val_ant = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p[\"place_value\"] = p.apply(lambda x: asignarPV(x[1], HGdics), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = p[['property_type','surface_total_in_m2',\\\n",
    "          'lat','lon','Cant_LocalesGastronomicos',\n",
    "         'Cant_ParadasTransporte', 'place_value', 'price_aprox_usd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrn, Xtest, Ytrn, Ytest = train_test_split(p[['property_type','surface_total_in_m2',\n",
    "        'place_value']],p[['price_aprox_usd']],test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hago algo similar con Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100725530206.132"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(criterion='mse',min_samples_leaf=3,min_samples_split=8, max_features = 'auto')\n",
    "ada = AdaBoostRegressor(n_estimators = 100,base_estimator = dt)\n",
    "\n",
    "ada.fit(Xtrn, Ytrn['price_aprox_usd'])\n",
    "aux = Ytest.copy()\n",
    "aux['predict'] = ada.predict(Xtest)\n",
    "\n",
    "error = mean_squared_error(Ytest['price_aprox_usd'] , aux['predict'])\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106931520418.42664"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(criterion='mse',min_samples_leaf=3,min_samples_split=8, max_features = 'auto')\n",
    "ada = AdaBoostRegressor(n_estimators = 110,base_estimator = dt)\n",
    "\n",
    "ada.fit(Xtrn, Ytrn['price_aprox_usd'])\n",
    "aux = Ytest.copy()\n",
    "aux['predict'] = ada.predict(Xtest)\n",
    "\n",
    "error = mean_squared_error(Ytest['price_aprox_usd'] , aux['predict'])\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109797360333.45287"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(criterion='mse',min_samples_leaf=3,min_samples_split=8, max_features = 'auto')\n",
    "ada = AdaBoostRegressor(n_estimators = 90,base_estimator = dt)\n",
    "\n",
    "ada.fit(Xtrn, Ytrn['price_aprox_usd'])\n",
    "aux = Ytest.copy()\n",
    "aux['predict'] = ada.predict(Xtest)\n",
    "\n",
    "error = mean_squared_error(Ytest['price_aprox_usd'] , aux['predict'])\n",
    "error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
